# Sampling Server Example

A comprehensive demonstration of **MCP sampling functionality** for AI model sampling through the Model Context Protocol. This example shows how MCP servers can request AI model generation from clients, enabling intelligent workflows and AI-assisted processing.

## Overview

MCP sampling allows servers to request AI model generation from clients through the `sampling/createMessage` endpoint. This enables powerful workflows where MCP servers can leverage AI models for content generation, analysis, and intelligent processing while maintaining separation of concerns between server logic and AI capabilities.

## Features

### ğŸ¤– **AI Model Integration**
- **Direct AI sampling** via `sampling/createMessage` endpoint
- **Model preferences** and constraints specification
- **Temperature and token controls** for generation quality
- **Context-aware prompting** with conversation history

### ğŸ’¬ **Conversational AI**
- **Multi-turn conversations** with message history
- **Context preservation** across sampling requests
- **Role-based messaging** (user, assistant)
- **Conversation metadata** tracking and management

### ğŸ’» **Specialized Sampling**
- **Code generation** with language-specific prompting
- **Creative writing** with style and genre controls
- **Technical analysis** with structured output formats
- **Problem-solving** with methodical approaches

### âš™ï¸ **Advanced Configuration**
- **Model hints** for optimal model selection
- **Cost budgets** and latency priorities
- **Stop sequences** and output constraints
- **Performance targets** and quality thresholds

## Quick Start

### 1. Start the Server

```bash
cargo run -p sampling-server
```

The server will start on `http://127.0.0.1:8051/mcp`

### 2. Test Sampling Endpoint

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "sampling/createMessage",
    "params": {
      "messages": [
        {
          "role": "user",
          "content": {
            "type": "text",
            "text": "Hello AI! Please introduce yourself."
          }
        }
      ]
    }
  }'
```

**Example Response:**
```json
{
  "result": {
    "message": {
      "role": "assistant",
      "content": {
        "type": "text",
        "text": "This is a sample message generated by the MCP server"
      }
    },
    "stop_reason": "stop"
  }
}
```

## Sampling Tools

### 1. Basic Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "basic_sampling",
      "arguments": {
        "prompt": "Explain quantum computing in simple terms"
      }
    }
  }'
```

### 2. Conversational Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "conversational_sampling",
      "arguments": {
        "user_message": "What are the benefits of renewable energy?",
        "conversation_context": "educational"
      }
    }
  }'
```

### 3. Code Generation Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "code_generation_sampling",
      "arguments": {
        "task_description": "Create a function to calculate Fibonacci numbers",
        "programming_language": "Python",
        "complexity_level": "intermediate"
      }
    }
  }'
```

### 4. Creative Writing Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "creative_writing_sampling",
      "arguments": {
        "writing_prompt": "A mysterious door appears in an ordinary room",
        "genre": "fantasy",
        "style": "atmospheric",
        "length": "medium"
      }
    }
  }'
```

### 5. Advanced Sampling Demo

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "advanced_sampling_demo",
      "arguments": {
        "task_type": "analysis",
        "complexity_level": "advanced",
        "output_format": "structured"
      }
    }
  }'
```

## Sampling Request Structure

### Basic Message Structure

```json
{
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "user|assistant",
        "content": {
          "type": "text",
          "text": "Message content here"
        }
      }
    ],
    "modelPreferences": {
      "hints": [{"name": "conversational"}, {"name": "helpful"}],
      "costPriority": 0.5,
      "speedPriority": 0.5,
      "intelligencePriority": 0.8
    },
    "systemPrompt": "You are a helpful AI assistant...",
    "temperature": 0.7,
    "maxTokens": 500,
    "stopSequences": ["```", "END"],
    "metadata": {
      "sessionId": "uuid-here",
      "taskType": "generation"
    }
  }
}
```

### Model Preferences

| Field | Description | Example Values |
|-------|-------------|----------------|
| `hints` | Model selection hints (objects with `name` field) | `[{"name": "conversational"}]` |
| `costPriority` | Cost optimization priority | `0.0` - `1.0` |
| `speedPriority` | Speed optimization priority | `0.0` - `1.0` |
| `intelligencePriority` | Intelligence optimization priority | `0.0` - `1.0` |

### Generation Parameters

| Parameter | Purpose | Range | Default |
|-----------|---------|-------|---------|
| `temperature` | Creativity vs precision | 0.0 - 1.0 | 0.7 |
| `maxTokens` | Response length limit | 1 - 4000 | 500 |
| `stopSequences` | Generation stop triggers | Array of strings | `[]` |

## Use Cases

### 1. **Content Generation Workflows**
- **Blog post creation** with topic and style specifications
- **Technical documentation** with code examples and explanations
- **Creative content** for marketing and storytelling
- **Educational materials** with appropriate complexity levels

### 2. **Code Development Assistance**
- **Algorithm implementation** with language-specific best practices
- **Code review and suggestions** with improvement recommendations  
- **Bug analysis and debugging** with step-by-step solutions
- **API documentation** with usage examples and patterns

### 3. **Interactive AI Applications**
- **Chatbot backends** with conversation state management
- **Virtual assistants** with context-aware responses
- **Educational tutors** with adaptive explanations
- **Creative writing partners** with collaborative storytelling

### 4. **Data Analysis and Insights**
- **Report generation** with structured analysis and conclusions
- **Data interpretation** with trend identification and insights
- **Research assistance** with source evaluation and synthesis
- **Decision support** with pros/cons analysis and recommendations

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Client        â”‚â”€â”€â”€â”€â”‚  Sampling Handler    â”‚â”€â”€â”€â”€â”‚  AI Model          â”‚
â”‚                     â”‚    â”‚                      â”‚    â”‚                     â”‚
â”‚ - Receives Request  â”‚    â”‚ - Process Parameters â”‚    â”‚ - Generate Content  â”‚
â”‚ - Invokes AI Model  â”‚    â”‚ - Build Prompts      â”‚    â”‚ - Apply Constraints â”‚
â”‚ - Returns Response  â”‚    â”‚ - Handle Context     â”‚    â”‚ - Optimize Output   â”‚
â”‚                     â”‚    â”‚ - Manage Sessions    â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  MCP Server Tools    â”‚
                           â”‚                      â”‚
                           â”‚ - Basic Sampling     â”‚
                           â”‚ - Conversational     â”‚
                           â”‚ - Code Generation    â”‚
                           â”‚ - Creative Writing   â”‚
                           â”‚ - Advanced Features  â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Advanced Features

### ğŸ¯ **Specialized Prompting**

```rust
let system_prompt = format!(
    "You are an expert {} programmer. Generate clean, well-documented, and efficient code. 
     Follow best practices for {} development. Complexity level: {}.",
    language, language, complexity
);

let request = CreateMessageRequest {
    messages: vec![user_message],
    model_preferences: Some(ModelPreferences {
        hints: Some(vec![ModelHint { name: Some("code_generation".to_string()) }, ModelHint { name: Some(language.to_lowercase()) }]),
        ..Default::default()
    }),
    system_prompt: Some(system_prompt),
    temperature: Some(0.3), // Lower for deterministic code
    max_tokens: Some(1500),
    // ...
};
```

### ğŸ”„ **Context Management**

```rust
// Build conversation history
let mut messages = vec![
    SamplingMessage {
        role: Role::Assistant,
        content: MessageContent::Text {
            text: "Hello! I'm ready to help.".to_string(),
        },
    },
    SamplingMessage {
        role: Role::User,
        content: MessageContent::Text {
            text: user_message.to_string(),
        },
    },
];

let request = CreateMessageRequest {
    messages,
    include_context: Some(IncludeContext::ThisServer),
    metadata: Some(serde_json::json!({
        "conversation_id": uuid,
        "context_type": "educational"
    })),
    // ...
};
```

### âš™ï¸ **Performance Optimization**

```rust
let request = CreateMessageRequest {
    model_preferences: Some(ModelPreferences {
        hints: Some(vec![ModelHint { name: Some("analytical".to_string()) }]),
        cost_priority: Some(0.5),
        speed_priority: Some(0.5),
        intelligence_priority: Some(0.8),
        ..Default::default()
    }),
    temperature: Some(0.4),               // Precise analysis
    max_tokens: Some(1000),               // Adequate length
    stop_sequences: Some(vec!["}".to_string()]), // JSON completion
    metadata: Some(serde_json::json!({
        "performance_target": {
            "max_latency_ms": 5000,
            "cost_budget": 0.05,
            "quality_threshold": 0.8
        }
    })),
    // ...
};
```

## Best Practices

### ğŸ¯ **Effective Prompting**
1. **Clear Instructions**: Provide specific, actionable prompts
2. **Context Setting**: Use system prompts to establish role and behavior
3. **Constraint Specification**: Define output format, length, and style requirements
4. **Example Provision**: Include examples for complex output formats

### âš¡ **Performance Optimization**
1. **Temperature Tuning**: Lower for factual content (0.3), higher for creativity (0.8)
2. **Token Management**: Set appropriate max_tokens to balance cost and completeness
3. **Stop Sequences**: Use to prevent over-generation and ensure format compliance
4. **Model Hints**: Provide hints for optimal model selection and behavior

### ğŸ”’ **Security and Quality**
1. **Input Validation**: Sanitize user inputs before sending to AI models
2. **Output Filtering**: Validate AI responses for appropriate content and format
3. **Cost Control**: Set reasonable cost budgets to prevent runaway expenses
4. **Error Handling**: Implement robust error handling for API failures

### ğŸ“Š **Monitoring and Analytics**
1. **Request Tracking**: Log sampling requests with metadata for analysis
2. **Performance Metrics**: Monitor latency, cost, and quality scores
3. **Usage Patterns**: Analyze which sampling types are most effective
4. **Quality Assessment**: Implement feedback mechanisms for continuous improvement

## Real-world Applications

### 1. **Content Management Systems**
- **Automated content creation** with brand voice consistency
- **SEO optimization** with keyword integration and readability analysis
- **Multi-language content** with cultural adaptation and localization
- **Content categorization** with automatic tagging and metadata

### 2. **Developer Tools**
- **Code generation IDEs** with context-aware suggestions
- **API documentation generators** with example code and explanations
- **Test case creation** with comprehensive scenario coverage
- **Code review assistants** with improvement recommendations

### 3. **Educational Platforms**
- **Personalized tutoring** with adaptive difficulty and explanations
- **Interactive learning** with question generation and assessment
- **Curriculum development** with age-appropriate content creation
- **Language learning** with conversation practice and corrections

### 4. **Business Intelligence**
- **Report automation** with data interpretation and insights
- **Market analysis** with trend identification and forecasting
- **Customer service** with intelligent response suggestions
- **Process optimization** with workflow analysis and recommendations

## Testing

```bash
# Start the server
cargo run -p sampling-server &

# Test basic sampling functionality
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "sampling/createMessage", "params": {"messages": [{"role": "user", "content": {"type": "text", "text": "Hello!"}}]}}'

# Test tool integration
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "tools/call", "params": {"name": "basic_sampling", "arguments": {"prompt": "Test prompt"}}}'

# Test advanced features
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "tools/call", "params": {"name": "advanced_sampling_demo", "arguments": {"task_type": "analysis"}}}'
```

This sampling server example demonstrates the full potential of MCP sampling for AI-assisted workflows, providing a foundation for building intelligent applications that leverage AI model capabilities while maintaining clean separation between server logic and AI generation.